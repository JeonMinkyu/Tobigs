{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "투빅스 과제\n",
    "==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여러분들은.... 할 수 있습니다...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. 아래와 같이 Data X와 Label Y 가 주어졌을 때, linear regression 적용을 위한 W의 dimension을 채워주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 이 cell은 수정하지 마세요.\n",
    "import numpy as np\n",
    "x = np.random.randn(100, 3)\n",
    "y = np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 이 부분을 채워 주시면 됩니다.\n",
    "w_dim_1 = \n",
    "w_dim_2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 이 cell은 수정하지 마세요.\n",
    "w = np.random.randn(w_dim_1, w_dim_2)\n",
    "pred = np.dot(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 이 cell은 수정하지 마세요.\n",
    "if pred.shape != y.shape:\n",
    "    print('틀렸을 가능성이 큽니다!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. 위의 문제를 확장하여 Neural Network의 feed forward 부분을 matrix 연산으로 생각하는 문제입니다. <br> 위의 문제와는 다르게 y가 integer로써 classification 문제입니다.\n",
    "##### 두개의 hidden layer를 가진 neural network를 구현할 건데요, 두 hidden layer의 node 수는 둘 다 100개 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 이 cell은 수정하지 마세요.\n",
    "x = np.random.randn(100, 3)\n",
    "y = np.random.randint(10, size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q 2-1. Weight matrix의 차원을 입력해주세요! (ans1, ans2, ... , ans6 부분을 바꿔주시면 됩니다.) <br><br>  참고 : np.random.randn(dim1, dim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 이 부분을 채워 주시면 됩니다.\n",
    "W_INPUT_HIDDEN = np.random.randn(ans1, ans2)\n",
    "W_HIDDEN_HIDDEN = np.random.randn(ans3, ans4)\n",
    "W_HIDDEN_OUTPUT = np.random.randn(ans5, ans6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 이 cell은 수정하지 마세요. \n",
    "f = lambda x: 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp)\n",
    "\n",
    "hidden1 = f(np.dot(x, W_INPUT_HIDDEN))\n",
    "hidden2 = f(np.dot(hidden1, W_HIDDEN_HIDDEN))\n",
    "output = softmax(np.dot(hidden2, W_HIDDEN_OUTPUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 이 cell은 수정하지 마세요.\n",
    "if len(y) != len(output):\n",
    "    print('틀렸을 가능성이 큽니다!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 2-2. 위의 문제에서 input layer -> hidden layer 1 , hidden layer 1 -> hidden layer 2 연산 부분에 bias term을 추가하려고 합니다! bias term의 차원을 써주세요 <br> <br> Hint : numpy broadcast (http://aikorea.org/cs231n/python-numpy-tutorial/#numpy-broadcasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 이 부분을 채워 주시면 됩니다. \n",
    "b1 = np.random.randn(ans1, ans2)\n",
    "b2 = np.random.randn(ans3, ans4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 이 cell은 수정하지 마세요.\n",
    "hidden1_1 = f(np.dot(x, W_INPUT_HIDDEN) + b1)\n",
    "hidden2_1 = f(np.dot(hidden1_1, W_HIDDEN_HIDDEN) + b2)\n",
    "output_1 = softmax(np.dot(hidden2_1, W_HIDDEN_OUTPUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 3. output_1과 y를 이용하여 최종 loss를 구하세요. (for문 사용 금지) <br><br> Hint : 01-Neural_Network.pdf에서 35페이지, 88페이지(regularization loss term은 무시하세요.), np.log함수를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 이 부분을 채워 주시면 됩니다."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
